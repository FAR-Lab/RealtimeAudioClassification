{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "In this notebook we take the generated images in the ``eneratedData`` folder and use them to train a neural network.\n",
    "\n",
    "### What does it all do?\n",
    "We will walk througho the main steps so you can understand in basics steps in this notebook. \n",
    "\n",
    "---\n",
    "\n",
    "First we need to import a couple of different libraries. You can see many of them contain the name ```troch```, this is the main machine learning library we will use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:25.120376Z",
     "start_time": "2020-08-02T21:29:25.114187Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classes to train\n",
    "\n",
    "The less classes you have  the fewer data you need. So slecting just the right ammount of classes can be one way to reduce the ammount of processing and increase, potentially, the reliabilty.\n",
    "\n",
    "In the following section you can select which of the found classes should be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:25.860651Z",
     "start_time": "2020-08-02T21:29:25.783158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Type=\"TRAINING\"\n",
    "exec(open(\"../helperFunctions.py\",\"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:41.596014Z",
     "start_time": "2020-08-02T21:29:41.590541Z"
    }
   },
   "outputs": [],
   "source": [
    "UsedClasses=[]\n",
    "for k in widgetDict:\n",
    "    if widgetDict[k].value==True:\n",
    "        UsedClasses.append(k)\n",
    "if(len(UsedClasses)<2):\n",
    "    print(\"Something is wrong here. we need at least 2 classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data set\n",
    "If test set is not defined previously, this function pulls a test set from the training set using a 80/20%split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T21:29:44.497868Z",
     "start_time": "2020-08-02T21:29:44.446826Z"
    }
   },
   "outputs": [],
   "source": [
    "classes =  tuple(UsedClasses)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainSets=[]\n",
    "testSets=[]\n",
    "\n",
    "for cl in classes:   \n",
    "    trainPath=os.path.join(SPECTRUM_IMAGES_ROOT,cl,'train')\n",
    "    if os.path.isdir (trainPath):\n",
    "        trainSets.append(SpectrumDataset(classes.index(cl),trainPath,transform))\n",
    "    else:\n",
    "        print('Coud not find path',trainPath);\n",
    "    \n",
    "    testPath=os.path.join(SPECTRUM_IMAGES_ROOT,cl,'test')\n",
    "    if os.path.isdir (testPath):\n",
    "        testSets.append(SpectrumDataset(classes.index(cl),testPath,transform))\n",
    "    else:\n",
    "        print('Coud not find path',testPath);\n",
    "\n",
    "\n",
    "lowestItemCount=np.inf\n",
    "classID=None\n",
    "for i,train in enumerate(trainSets):\n",
    "    if(lowestItemCount>len(train)):\n",
    "        lowestItemCount=len(train)\n",
    "        classID=i\n",
    "        lowestItemCount=len(train)\n",
    "for i in range(len(trainSets)):\n",
    "    trainSets[i].ReduceSize(lowestItemCount)\n",
    "    \n",
    "\n",
    "TrainDataSet = torch.utils.data.ConcatDataset(trainSets)\n",
    "TestDataSet = torch.utils.data.ConcatDataset(testSets)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(TrainDataSet, batch_size=16, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(TestDataSet, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview sample training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes an entire training batch of images and displays them with their respective labels. Have a look and verify that indeed you see spectrograph images that look similar to what you saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:11.509950Z",
     "start_time": "2020-08-02T20:42:09.463804Z"
    }
   },
   "outputs": [],
   "source": [
    "#Getting some random training images and showing them\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "for i in range(trainloader.batch_size):\n",
    "    imshow(images[i])\n",
    "    print(classes[labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify use of Graphics Card (if there is one) and use ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:11.649015Z",
     "start_time": "2020-08-02T20:42:11.511342Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model \n",
    "The model '../Models/MainModelUrban.pth' was trained on the UrbanSound dataset; other models could be specified instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:36:02.653653Z",
     "start_time": "2020-08-02T20:36:02.539338Z"
    }
   },
   "outputs": [],
   "source": [
    "ModelData = torch.load('../Models/MainModelUrban.pth',map_location='cpu')\n",
    "model.load_state_dict(ModelData['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting off the head\n",
    "In the following cell, the setting 'param.requires_grad = False' is **the** function that is telling the network to only retrain the last layer. If you set this parameter to True, the training will take much longer, but hopefully be better at predicting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:16.669357Z",
     "start_time": "2020-08-02T20:42:16.661468Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For each parameter in the network we turn of training, \n",
    "by setting  .requires_grad  to `False`.\n",
    "\n",
    "This makes sure that the computer will not try to adjust thos variables when \"training\".\n",
    "'''\n",
    "for param in model.parameters(): #\n",
    "    param.requires_grad = False #... \n",
    "    \n",
    "'''\n",
    "'fc' stands for \"fully connected\" and it is the very last layer in the neural net.\n",
    "We replace this layer with a new fully connected layer, that connects the 512 input neurons to neurons for our classes.\n",
    "'''    \n",
    "model.fc = nn.Linear(512, len(classes)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move model to GPU (if there is a GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:42:23.491845Z",
     "start_time": "2020-08-02T20:42:23.481809Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train_epoch_losses=[]\n",
    "test_epoch_losses=[]\n",
    "epoch=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:00.245670Z",
     "start_time": "2020-08-02T20:42:29.699734Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training the network on the training dataset\n",
    "for i in range(5):  # loop over the dataset multiple (5) times \n",
    "    epoch+=1\n",
    "    print(\"Starting epoch:\",epoch)\n",
    "    epochLoss=0.0\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #print(\"Running Batches\",i)\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        if device.type=='cuda':\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        if((i+i)%50==0):\n",
    "            if(i>0):\n",
    "                print('Processed images:',i*trainloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epochLoss+=loss.item()\n",
    "        \n",
    "    \n",
    "    model.eval()\n",
    "    testLoss=0\n",
    "    print(\"About to test the performance on the test set.\")\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            if device.type=='cuda':\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            testLoss+=loss.item()\n",
    "            if(i%50==0):\n",
    "                if(i>0):\n",
    "                    print('Tested images:',i*testloader.batch_size,'. Running Timer @ {:.2f}sec.'.format(time.time()-t0))\n",
    "\n",
    "\n",
    "    train_epoch_losses.append(epochLoss/len(trainloader))\n",
    "    test_epoch_losses.append(testLoss/len(testloader))\n",
    "    EpochLength = time.time()-t0\n",
    "    print('{} train loss: {:.3f} and test loss: {:.3f}, and it took us: {:.2f} seconds.'.format (epoch + 1, epochLoss / len(trainloader),testLoss/len(testloader),EpochLength))  # DAVID CHanged it to 1000 from 2000 not sure if thats totally done\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post training analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training has finished, save information about the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:08.058441Z",
     "start_time": "2020-08-02T20:44:07.767189Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving the learnd model in file that can be loaded in for inference\n",
    "torch.save({\n",
    "    'model':model.state_dict(),\n",
    "    'classes':classes,\n",
    "    'resolution':224,\n",
    "    'modelType':\"resnet18\" # <= If you try out different models make sure to change this too\n",
    "},\"../models/CatDogResNet.pth\") # <=Edit file name here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display how the traing and test loss progressed over successive epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:09.700714Z",
     "start_time": "2020-08-02T20:44:09.070817Z"
    }
   },
   "outputs": [],
   "source": [
    "#Displaying how the loss progresses over time.\n",
    "plt.plot(train_epoch_losses, label='Training Loss',c='r')\n",
    "plt.plot(test_epoch_losses, label='Test Loss',c='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show spectagrams, Predicted and Actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:12.759024Z",
     "start_time": "2020-08-02T20:44:12.697637Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print predicted and acual labels for Spectragrams\n",
    "model.eval()\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "for i in range(trainloader.batch_size):\n",
    "    imshow(images[i].cpu())\n",
    "    print('GroundTruth: ',classes[labels[i]])\n",
    "    print('Predicted: ',  classes[predicted[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print accuracy of test predictions for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T20:44:15.905168Z",
     "start_time": "2020-08-02T20:44:14.974999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Network analytics\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "class_total = list(0. for i in range(len(classes)))\n",
    "model.eval()\n",
    "allLabels=[]\n",
    "allPrediction=[]\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        if (c.dim()==0):\n",
    "            continue\n",
    "        for i in range(testloader.batch_size):\n",
    "            if(len(labels)<=i):\n",
    "                continue;\n",
    "            label = labels[i]\n",
    "            allLabels.append(labels[i].to('cpu').numpy())\n",
    "            allPrediction.append(predicted[i].to('cpu').numpy())\n",
    "            #print (c.shape)\n",
    "            if(testloader.batch_size>1):\n",
    "\n",
    "                class_correct[label] += c[i].item()\n",
    "            else:\n",
    "                class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(confusion_matrix(allLabels, allPrediction))\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Epoch:\n",
    "[[2126 1362]\n",
    " [ 426 4373]]\n",
    "Accuracy of  Dogs : 60 %\n",
    "Accuracy of  Cats : 91 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
